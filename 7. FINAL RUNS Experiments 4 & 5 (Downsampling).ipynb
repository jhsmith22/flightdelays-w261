{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d23632b-a38d-48a6-b789-a5815f17e12d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Flight Prediction Machine Learning Estimator Experiments 4-5\n",
    "This code estimates random forest and neural network models and prints out evaluation metrics (f-beta, where beta=2 and AUC). The code is working with the cleaned training dataset from 2015-2018. This dataset HAS been downsampled to correct for class imbalance. This code also selects the Final Model as the neural network 3 architecture and uses that model to predict the heldout test dataset.\n",
    "\n",
    "Our final model shows marked improvement from baseline, using a more predictive set of features and downsampling the majority class, predicting the full 2015-2018 training with a f-beta of 63%. We used this final model built on the training set to predict the unseen, held-out 2019 data, which is the best and final assessment of the power of our model, achieving a middling f-beta score of 54%. In our current form, our model's f-beta metric is insufficient to provide a useful tool for industry.  This implies that our features are not rich enough to represent the complex set of factors that cause flight delays. The report's conclusion discusses several directions for future work to improve this predictive tool.\n",
    "\n",
    "![Pipeline Image](https://i.imgur.com/wq62T0E.png)\n",
    "\n",
    "### Project Description\n",
    "This is a group project conducted for course w261: Machine Learning at Scale at the University of California Berkeley in Summer 2023. This project develops a machine learning model that predicts flight delays based on historical flight, airport station, and weather data spanning five years from 2015-2019 in the United States.\n",
    "\n",
    "###Group members\n",
    "Jessica Stockham, Chase Madison, Kisha Kim, Eric Danforth\n",
    "\n",
    "Citation: Code written by Jessica Stockham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c929815-fd73-4edd-b566-6282526ca6ba",
     "showTitle": true,
     "title": "Import Packages"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from datetime import datetime, timedelta, date\n",
    "import holidays\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "\n",
    "from pyspark.sql.functions import udf, col,isnan,when,count\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler,StandardScaler, Imputer, Bucketizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.spark import SparkXGBClassifier\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from hyperopt import fmin, tpe, Trials, SparkTrials, hp, space_eval\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17823aab-96be-4509-bb51-5c5a0fd012d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Place this cell in any team notebook that needs access to the team cloud storage\n",
    "mids261_mount_path = '/mnt/mids-w261'  # 261 course blob storage is mounted here\n",
    "secret_scope = 'sec5-team1-scope'  # Name of the secret scope Chase created in Databricks CLI\n",
    "secret_key = 'sec5-team1-key'  # Name of the secret key Chase created in Databricks CLI\n",
    "storage_account = 'sec5team1storage'  # Name of the Azure Storage Account Chase created\n",
    "blob_container = 'sec5-team1-container'  # Name of the container Chase created in Azure Storage Account\n",
    "team_blob_url = f'wasbs://{blob_container}@{storage_account}.blob.core.windows.net'  # Points to the root of your team storage bucket\n",
    "spark.conf.set(  # SAS Token: Grant the team limited access to Azure Storage resources\n",
    "  f'fs.azure.sas.{blob_container}.{storage_account}.blob.core.windows.net',\n",
    "  dbutils.secrets.get(scope=secret_scope, key=secret_key)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36d12c42-c3c2-4b10-b149-5ba764443f3b",
     "showTitle": true,
     "title": "Load Data"
    }
   },
   "outputs": [],
   "source": [
    "##### LOAD 60 MONTH DATASET ##########\n",
    "timeInterval = '60mo'\n",
    "\n",
    "# TRAIN DATASET: 2015-2018\n",
    "fold_name_clean = 'train_clean_downsampled'\n",
    "train = spark.read.format(\"parquet\")\\\n",
    "    .option(\"path\", (f\"{team_blob_url}/{fold_name_clean}/rapid\" + timeInterval))\\\n",
    "    .load().cache()\n",
    "\n",
    "# TEST DATASET: 2019\n",
    "fold_name_clean = 'test_clean_downsampled'\n",
    "test = spark.read.format(\"parquet\")\\\n",
    "    .option(\"path\", (f\"{team_blob_url}/{fold_name_clean}/rapid\" + timeInterval))\\\n",
    "    .load().cache()\n",
    "\n",
    "# Result List to Hold the Trained Models and Resulting Fscore\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efd84140-ab58-49c3-ad19-d8890007d3d0",
     "showTitle": true,
     "title": "Experiment #4: Random Forest Experiment Architecture 2"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Start: 2023-08-10 20:43:04.550172\nModel built: 2023-08-10 21:07:12.287360\nPredicted Train: 2023-08-10 21:07:12.403078\n0.6038293179995597\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/spark/python/pyspark/sql/context.py:165: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.7195318696947894\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/08/10 21:11:48 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n2023/08/10 21:13:24 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/de79ece40969423dbf3c2504c4343d92/76ac679a643b47eb8ac43dd8bda0b1cb/artifacts/rf_model/sparkml, flavor: spark), fall back to return ['pyspark==3.4.0']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[label: double, DISTANCE: double, ELEVATION: double, FE_PRIOR_DAILY_AVG_DEP_DELAY: double, FE_PRIOR_AVG_DURATION: double, FE_NUM_FLIGHT_SCHEDULED: bigint, DEP_DELAY_LAG: double, DAY_OF_WEEK: int, MONTH: int, YEAR: int, OP_UNIQUE_CARRIER: string, origin_type: string, dest_type: string, is_holiday_double: double, is_holiday_adjacent_double: double, IS_FIRST_FLIGHT_OF_DAY_double: double, DATE: timestamp, FL_DATE: date, OP_CARRIER_FL_NUM: int, DEP_DELAY: double, AIR_TIME: double, DEP_TIME_BLK: string, origin_iata_code: string, dest_iata_code: string, TAIL_NUM: string, sched_depart_date_time_UTC: timestamp, CRS_DEP_TIME: int, ORIGIN: string, DEST: string, CRS_DEP_BUCKET: double, DAY_OF_WEEK_ix: double, MONTH_ix: double, YEAR_ix: double, OP_UNIQUE_CARRIER_ix: double, origin_type_ix: double, dest_type_ix: double, is_holiday_double_ix: double, is_holiday_adjacent_double_ix: double, IS_FIRST_FLIGHT_OF_DAY_double_ix: double, CRS_DEP_BUCKET_ix: double, DAY_OF_WEEK_hot: vector, MONTH_hot: vector, YEAR_hot: vector, OP_UNIQUE_CARRIER_hot: vector, origin_type_hot: vector, dest_type_hot: vector, is_holiday_double_hot: vector, is_holiday_adjacent_double_hot: vector, IS_FIRST_FLIGHT_OF_DAY_double_hot: vector, CRS_DEP_BUCKET_hot: vector, pagerank_origin: double, triangle_count_origin: bigint, pagerank_dest: double, triangle_count_dest: bigint, DISTANCE_imputed: double, ELEVATION_imputed: double, FE_PRIOR_DAILY_AVG_DEP_DELAY_imputed: double, FE_PRIOR_AVG_DURATION_imputed: double, FE_NUM_FLIGHT_SCHEDULED_imputed: bigint, DEP_DELAY_LAG_imputed: double, pagerank_origin_imputed: double, pagerank_dest_imputed: double, triangle_count_origin_imputed: bigint, triangle_count_dest_imputed: bigint, vectorized_numeric_features: vector, scaled_numeric: vector, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Job Start: {datetime.now()}')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    estimator = RandomForestClassifier(featuresCol = 'features'\n",
    "                                , labelCol = 'label'\n",
    "                                , maxDepth = 12\n",
    "                                , numTrees = 140\n",
    "                                )    \n",
    "  \n",
    "    model = estimator.fit(train)\n",
    "\n",
    "    print(f'Model built: {datetime.now()}')\n",
    "\n",
    "    # Predict TRAIN\n",
    "    pred_train = model.transform(train).cache()\n",
    "\n",
    "    print(f'Predicted Train: {datetime.now()}')\n",
    "\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"fMeasureByLabel\", beta=2.0, metricLabel=1.0)\n",
    "    fmeasure = evaluator.evaluate(pred_train, {evaluator.metricLabel: 1.0})\n",
    "    print(fmeasure)\n",
    "\n",
    "    results.append(['rf', model, fmeasure])\n",
    "\n",
    "    pred_train_rdd=pred_train.select('prediction', 'label').rdd\n",
    "    metrics = BinaryClassificationMetrics(pred_train_rdd)\n",
    "\n",
    "    # Area under ROC curve\n",
    "    print(\"Area under ROC = %s\" % metrics.areaUnderROC)\n",
    "\n",
    "    # Log Model and Metric\n",
    "    mlflow.spark.log_model(model, \"rf_model\")\n",
    "    mlflow.log_metric(\"FULLTRAIN_rf_fbeta\", fmeasure)\n",
    "    mlflow.log_metric(\"FULLTRAIN_rf_AUC\", fmeasure)\n",
    "\n",
    "# End prior mlfow run\n",
    "mlflow.end_run()\n",
    "\n",
    "# Save prediction df on training to blob\n",
    "fold_name_clean = 'final_train_results_downsampled'\n",
    "pred_train.write.format(\"parquet\").mode(\"overwrite\")\\\n",
    "    .option(\"path\", (f\"{team_blob_url}/{fold_name_clean}/rf_train_pred_df\" + timeInterval))\\\n",
    "    .save()\n",
    "\n",
    "pred_train.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c558a9d-77f6-4056-a035-32194653bbd3",
     "showTitle": true,
     "title": "Experiment 5: Neural Network Architecture 3"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\nModel built: 2023-08-10 21:38:05.744856\nPredicted Train: 2023-08-10 21:38:06.051885\n0.6307053558466028\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/08/10 21:39:21 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[label: double, DISTANCE: double, ELEVATION: double, FE_PRIOR_DAILY_AVG_DEP_DELAY: double, FE_PRIOR_AVG_DURATION: double, FE_NUM_FLIGHT_SCHEDULED: bigint, DEP_DELAY_LAG: double, DAY_OF_WEEK: int, MONTH: int, YEAR: int, OP_UNIQUE_CARRIER: string, origin_type: string, dest_type: string, is_holiday_double: double, is_holiday_adjacent_double: double, IS_FIRST_FLIGHT_OF_DAY_double: double, DATE: timestamp, FL_DATE: date, OP_CARRIER_FL_NUM: int, DEP_DELAY: double, AIR_TIME: double, DEP_TIME_BLK: string, origin_iata_code: string, dest_iata_code: string, TAIL_NUM: string, sched_depart_date_time_UTC: timestamp, CRS_DEP_TIME: int, ORIGIN: string, DEST: string, CRS_DEP_BUCKET: double, DAY_OF_WEEK_ix: double, MONTH_ix: double, YEAR_ix: double, OP_UNIQUE_CARRIER_ix: double, origin_type_ix: double, dest_type_ix: double, is_holiday_double_ix: double, is_holiday_adjacent_double_ix: double, IS_FIRST_FLIGHT_OF_DAY_double_ix: double, CRS_DEP_BUCKET_ix: double, DAY_OF_WEEK_hot: vector, MONTH_hot: vector, YEAR_hot: vector, OP_UNIQUE_CARRIER_hot: vector, origin_type_hot: vector, dest_type_hot: vector, is_holiday_double_hot: vector, is_holiday_adjacent_double_hot: vector, IS_FIRST_FLIGHT_OF_DAY_double_hot: vector, CRS_DEP_BUCKET_hot: vector, pagerank_origin: double, triangle_count_origin: bigint, pagerank_dest: double, triangle_count_dest: bigint, DISTANCE_imputed: double, ELEVATION_imputed: double, FE_PRIOR_DAILY_AVG_DEP_DELAY_imputed: double, FE_PRIOR_AVG_DURATION_imputed: double, FE_NUM_FLIGHT_SCHEDULED_imputed: bigint, DEP_DELAY_LAG_imputed: double, pagerank_origin_imputed: double, pagerank_dest_imputed: double, triangle_count_origin_imputed: bigint, triangle_count_dest_imputed: bigint, vectorized_numeric_features: vector, scaled_numeric: vector, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the maximum number of features across all folds\n",
    "num_features = len([x[\"name\"] for x in sorted(train.schema[\"features\"].metadata[\"ml_attr\"][\"attrs\"][\"binary\"] + train.schema[\"features\"].metadata[\"ml_attr\"][\"attrs\"][\"numeric\"], key=lambda x: x[\"idx\"])])\n",
    "print(num_features)\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Estimator\n",
    "    estimator = MultilayerPerceptronClassifier(layers=[num_features, 8, 4, 2], seed=42, labelCol='label', featuresCol='features')\n",
    "\n",
    "    model = estimator.fit(train)\n",
    "\n",
    "    print(f'Model built: {datetime.now()}')\n",
    "\n",
    "    # Predict TRAIN\n",
    "    pred_train = model.transform(train).cache()\n",
    "\n",
    "    print(f'Predicted Train: {datetime.now()}')\n",
    "\n",
    "    # f-beta\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"fMeasureByLabel\", beta=2.0, metricLabel=1.0)\n",
    "    fmeasure = evaluator.evaluate(pred_train, {evaluator.metricLabel: 1.0})\n",
    "    print(fmeasure)\n",
    "\n",
    "    results.append(['nn', model, fmeasure])\n",
    "\n",
    "    # AUC\n",
    "    pred_train_rdd=pred_train.select('prediction', 'label').rdd\n",
    "    metrics = BinaryClassificationMetrics(pred_train_rdd)\n",
    "    print(\"Area under ROC = %s\" % metrics.areaUnderROC)\n",
    "\n",
    "    # Log Model and Metric\n",
    "    mlflow.spark.log_model(model, \"nn_model\")\n",
    "    mlflow.log_metric(\"FULLTRAIN_nn_fbeta\", fmeasure)\n",
    "    mlflow.log_metric(\"FULLTRAIN_nn_AUC\", fmeasure)\n",
    "\n",
    "# End prior mlfow run\n",
    "mlflow.end_run()\n",
    "\n",
    "# Save prediction df on training to blob\n",
    "fold_name_clean = 'final_train_results'\n",
    "pred_train.write.format(\"parquet\").mode(\"overwrite\")\\\n",
    "    .option(\"path\", (f\"{team_blob_url}/{fold_name_clean}/nn_train_pred_df\" + timeInterval))\\\n",
    "    .save()\n",
    "\n",
    "pred_train.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73c37a7d-320f-4492-87d4-2a99dc38aa25",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.7179599425810118\n"
     ]
    }
   ],
   "source": [
    "# Area under ROC curve\n",
    "pred_train_rdd=pred_train.select('prediction', 'label').rdd\n",
    "metrics = BinaryClassificationMetrics(pred_train_rdd)\n",
    "print(\"Area under ROC = %s\" % metrics.areaUnderROC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba4aad1d-afc4-4f3c-be5b-0b5723bbaa65",
     "showTitle": true,
     "title": "PREDICT 2019 HELDOUT TEST SET"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted TEST: 2023-08-10 21:47:14.764984\n0.5438489280208696\n"
     ]
    }
   ],
   "source": [
    "# Predict TEST with model from Experiment 5 (Neural Network Architecture #3)\n",
    "pred_test = model.transform(test).cache()\n",
    "\n",
    "print(f'Predicted TEST: {datetime.now()}')\n",
    "\n",
    "# f-beta#\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"fMeasureByLabel\", beta=2.0, metricLabel=1.0)\n",
    "fmeasure = evaluator.evaluate(pred_test, {evaluator.metricLabel: 1.0})\n",
    "print(fmeasure)\n",
    "\n",
    "results.append(['nn', model, fmeasure])\n",
    "\n",
    "pred_test.unpersist()\n",
    "\n",
    "# Save prediction df on heldout to blob\n",
    "timeInterval = '60mo'\n",
    "fold_name_clean = 'final_heldout_results_downsampled'\n",
    "pred_test.write.format(\"parquet\").mode(\"overwrite\")\\\n",
    "    .option(\"path\", (f\"{team_blob_url}/{fold_name_clean}/nn_heldout_pred_df\" + timeInterval))\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "071b9b45-0d3d-4017-bab3-adc5b37cd9a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.7093227111384619\n"
     ]
    }
   ],
   "source": [
    "# AUC\n",
    "pred_test_rdd=pred_test.select('prediction', 'label').rdd\n",
    "metrics = BinaryClassificationMetrics(pred_test_rdd)\n",
    "\n",
    "# Area under ROC curve\n",
    "print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "FINAL RUNS Experiments 4 & 5 (Downsampling)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
